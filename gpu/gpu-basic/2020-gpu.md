---
title: 人工智能研究者应该选择哪款显卡？
keywords: CUDA, GPU, 硬件, 人工智能, 深度学习, Titan RTX, 2080 Ti, V100
summary: ""

chapter-name: GPU基础知识
chapter-url: /gpu/gpu-basic/index.html
---

2020 年，什么样的 GPU 才是人工智能训练的最佳选择？

上一节我们曾简单介绍英伟达为优化深度学习的矩阵运算，在较新的微架构中，专门设计了Tensor Core这样的混合精度核心，因此，人工智能训练最好选择带有Tensor Core的GPU。

众所周知，当今业界领先（State-of-the-art）的深度学习模型都会占用巨大的显存空间，很多过去性能算得上强劲的 GPU，现在可能稍显内存不足。Lambda实验室2020年2月发布了一篇显卡横向测评[文章](https://lambdalabs.com/blog/choosing-a-gpu-for-deep-learning/)，探讨了哪些GPU可以在不出现内存错误的情况下训练模型。核心结论是，显存大小非常重要。是的，显存大小正在制约着很多深度学习模型的训练。

因为深度学习技术的突飞猛进，以前 12G 内存打天下的局面不复存在了。2020 年 2 月，你至少需要花费 2500 美元买上一块英伟达最新款的 Titan RTX 才可以勉强跑通业界性能最好的模型——那到今年年底会是什么样就无法想象了。

对于个人用户，英伟达消费级的GeForce系列是首选。比较经济的选项有：

* GeForce RTX 2080 Ti：1200美元，11GB显存，Turing微架构（支持Tensor Core）
* Titan RTX：2500美元，24GB显存， Turing微架构（支持Tensor Core）
* Quadro RTX 6000：4000美元，24GB显存，Turing微架构（支持Tensor Core）
* Quadro RTX 8000：5500美元，48GB显存，Turing微架构（支持Tensor Core）

数据中心的GPU则显然更贵，适合企业级用户：

* Telsa V100：16或32GB显存两个版本，PCI-E和NVLink两个版本，Volta微架构（支持Tensor Core）
* Telsa V100S：32GB显存，PCI-E总线，Volta微架构（支持Tensor Core）

如果进行深度学习研究，GeForce RTX 2080 Ti（11GB）可能是起步标配；Titan RTX（24GB）是个不错的选项，兼顾了价格、显存和计算性能；Quadro RTX 8000（48GB）、Telsa V100（32GB）等显卡适合深度学习领域的前沿研究人员。

在物理硬件昂贵的当下，或许我们应该把目光转向云端GPU。