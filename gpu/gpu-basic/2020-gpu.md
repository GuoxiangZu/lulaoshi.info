---
title: 人工智能研究者应该选择哪款显卡？
keywords: CUDA, GPU, 硬件, 人工智能, 深度学习, Titan RTX, 2080 Ti, V100
summary: ""

chapter-name: GPU基础知识
chapter-url: /gpu/gpu-basic/index.html
---

2020 年，什么样的 GPU 才是人工智能训练的最佳选择？

上一节我们曾简单介绍英伟达为优化深度学习的矩阵运算，在较新的微架构中，专门设计了Tensor Core这样的混合精度核心，因此，人工智能训练最好选择带有Tensor Core的GPU。

众所周知，当今业界领先（State-of-the-art）的深度学习模型都会占用巨大的显存空间，很多过去性能算得上强劲的 GPU，现在可能稍显内存不足。Lambda实验室2020年2月发布了一篇显卡横向测评[文章](https://lambdalabs.com/blog/choosing-a-gpu-for-deep-learning/)，探讨了哪些GPU可以在不出现内存错误的情况下训练模型。核心结论是，显存大小非常重要。是的，显存大小正在制约着很多深度学习模型的训练。

因为深度学习技术的突飞猛进，以前 12G 内存打天下的局面不复存在了。2020 年 2 月，你至少需要花费 2500 美元买上一块英伟达最新款的 Titan RTX 才可以勉强跑通业界性能最好的模型——那到今年年底会是什么样就无法想象了。

## 消费级

对于个人用户，英伟达消费级的GeForce系列是首选。比较经济的选项有：

* GeForce RTX 2080 Ti：1200美元，11GB显存，Turing微架构（支持Tensor Core）
* Titan RTX：2500美元，24GB显存， Turing微架构（支持Tensor Core）

需要注意的是，这些消费级显卡对多卡并行支持不好，默认情况，他们不支持多卡间直接通信，如果我们希望卡1和卡2之间相互通信，那么数据通过PCI-E总线在多卡之间通信，这种方式不利于多卡之间的通信。2080 Ti和Titan RTX对于多卡之间PCI-E通道的P2P（Peer-to-Peer）通信支持并不好，但并不意味着他们不支持NVLink，用户可以通过购买NVLink桥接器来构建多卡之间的通信通道。有人称这个问题是这两款GPU的设计缺陷，也有人认为英伟达有意为之，为的是让有多卡并行计算需求的人去购买Telsa系列GPU。

## 企业级

数据中心的GPU产品更贵，适合企业级用户，它们的显存更高，也可以更好地支持多卡并行。

* Quadro RTX 6000：4000美元，24GB显存，Turing微架构（支持Tensor Core）
* Quadro RTX 8000：5500美元，48GB显存，Turing微架构（支持Tensor Core）
* Telsa V100：16或32GB显存两个版本，PCI-E和NVLink两个版本，Volta微架构（支持Tensor Core）
* Telsa V100S：32GB显存，PCI-E总线，Volta微架构（支持Tensor Core）

企业级的GPU一般都必须插到服务器或工作站上，这些服务器和工作站本身也不便宜，尤其是支持Telsa平台的服务器在十万元级别。当然，这里没有考虑机房建设、电费等成本。

2020年5月英伟达GTC 2020上发布了新一代Ampere微架构以及Telsa A100显卡，A100显卡的人工智能训练和推理能力更强，而且单个A100可以被分割成最多7个独立GPU来处理各种计算任务。

有多卡并行训练任务的朋友，建议选择支持NVLink的Telsa系列显卡。

## 小结

如果进行深度学习研究，GeForce RTX 2080 Ti（11GB）可能是起步标配；Titan RTX（24GB）是个不错的选项，兼顾了价格、显存和计算性能。对于企业级用户，Quadro RTX 8000（48GB）、Telsa V100（32GB）等显卡适合深度学习领域的前沿研究人员。2020年下半年，英伟达新的计算平台即将出货，新产品一方面会带来更强大的性能，另一方面也会使现有产品降价。

在物理硬件昂贵的当下，或许我们应该把目光转向云端GPU。